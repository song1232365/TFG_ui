# 项目配置文档

本文档提供完整的项目配置和运行指南，帮助老师快速复现项目。

---

## 目录

1. [一、环境准备](#一环境准备)
2. [二、克隆仓库](#二克隆仓库)
3. [三、Docker环境配置](#三docker环境配置)
4. [四、项目启动](#四项目启动)
5. [五、OpenFace 使用说明（重要）](#五openface-使用说明重要)
6. [六、功能使用流程](#六功能使用流程)
7. [七、评测功能](#七评测功能)
8. [八、常见问题](#八常见问题)

---

## 一、环境准备

### 1.1 硬件要求

- **GPU**：NVIDIA GPU，支持CUDA 11.8+，至少8GB显存（推荐16GB+）
- **内存**：至少16GB RAM（推荐32GB+）
- **磁盘空间**：至少100GB可用空间（推荐200GB+）
- **网络**：需要稳定的网络连接（用于下载模型和依赖）

### 1.2 软件要求

- **操作系统**：Ubuntu 20.04+ / CentOS 7+ / 其他Linux发行版
- **Docker**：20.10+（必须）
- **Docker Compose**：1.29+（推荐）
- **NVIDIA Docker**：支持GPU（`nvidia-docker2`）

### 1.3 检查GPU和Docker

```bash
# 检查GPU
nvidia-smi

# 检查Docker
docker --version
docker-compose --version

# 检查NVIDIA Docker支持
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

如果上述命令执行失败，请参考 `DOCKER完整指南.md` 进行安装。

---

## 二、克隆仓库

### 2.1 克隆主仓库

```bash
# 克隆项目仓库
git clone <仓库地址> TFG_ui
cd TFG_ui
```

### 2.2 初始化Git子模块（重要！）

项目包含Git子模块，必须初始化才能正常使用：

```bash
# 进入TalkingGaussian目录
cd TalkingGaussian

# 初始化并更新子模块
git submodule update --init --recursive

# 或者使用以下命令（一步完成）
git submodule update --init --recursive --depth 1
```

**子模块说明**：
- `submodules/simple-knn`：用于Gaussian Splatting的KNN加速
- `submodules/diff-gaussian-rasterization`：Gaussian Splatting的光栅化实现
- `third_party/Wav2Lip`：用于唇形同步的Wav2Lip工具
- `third_party/syncnet_python`：用于唇形同步评估的SyncNet工具

**验证子模块**：
```bash
# 检查子模块是否已初始化
ls -la submodules/simple-knn/
ls -la submodules/diff-gaussian-rasterization/
ls -la third_party/Wav2Lip/
ls -la third_party/syncnet_python/

# 如果目录为空或不存在，说明子模块未初始化
```

### 2.3 如果子模块初始化失败

#### 问题1：网络问题导致初始化失败

如果网络问题导致子模块初始化失败，可以手动处理：

```bash
cd TalkingGaussian

# 方法1：使用代理或镜像（如果有）
git config --global url."https://github.com/".insteadOf "git@github.com:"

# 方法2：手动克隆子模块
cd submodules
git clone https://github.com/ashawkey/diff-gaussian-rasterization.git
git clone https://gitlab.inria.fr/bkerbl/simple-knn.git
cd ../third_party
git clone https://github.com/Rudrabha/Wav2Lip.git
git clone https://github.com/joonson/syncnet_python.git
cd ..
```

#### 问题2：`.gitmodules` 文件缺失子模块配置（常见问题）

**错误信息**：
```
fatal: No url found for submodule path 'submodules/diff-gaussian-rasterization' in .gitmodules
```
或
```
fatal: No url found for submodule path 'third_party/Wav2Lip' in .gitmodules
```

**原因**：`.gitmodules` 文件中缺少某些子模块的URL配置，但Git索引中已注册了这些子模块。

**解决方案**：

1. **检查 `.gitmodules` 文件**：
```bash
cd TalkingGaussian
cat .gitmodules
```

2. **如果文件不完整，手动添加缺失的配置**：

编辑 `TalkingGaussian/.gitmodules` 文件，确保包含以下所有子模块配置：

```ini
[submodule "submodules/simple-knn"]
	path = submodules/simple-knn
	url = https://gitlab.inria.fr/bkerbl/simple-knn.git
[submodule "submodules/diff-gaussian-rasterization"]
	path = submodules/diff-gaussian-rasterization
	url = https://github.com/ashawkey/diff-gaussian-rasterization.git
[submodule "third_party/Wav2Lip"]
	path = third_party/Wav2Lip
	url = https://github.com/Rudrabha/Wav2Lip.git
[submodule "third_party/syncnet_python"]
	path = third_party/syncnet_python
	url = https://github.com/joonson/syncnet_python.git
```

3. **清理并重新初始化子模块**：

```bash
cd TalkingGaussian

# 从Git索引中移除有问题的子模块
git rm --cached third_party/Wav2Lip third_party/syncnet_python 2>/dev/null || true
git rm --cached submodules/diff-gaussian-rasterization submodules/simple-knn 2>/dev/null || true

# 清理Git子模块缓存
Remove-Item -Recurse -Force .git\modules\* -ErrorAction SilentlyContinue  # Windows PowerShell
# 或
rm -rf .git/modules/*  # Linux/Mac

# 重新同步子模块配置
git submodule sync

# 重新初始化子模块
git submodule update --init --recursive
```

4. **验证修复**：

```bash
# 检查子模块状态
git submodule status

# 检查子模块目录是否存在
ls -la submodules/
ls -la third_party/
```

**注意**：如果子模块目录已经存在且有内容，`git submodule update --init --recursive` 可能不会重新下载。对于Docker构建来说，只要目录存在，Dockerfile中的安装步骤就能正常工作。

---

## 三、Docker环境配置

### 3.1 配置Docker镜像加速（推荐）

如果在中国大陆，建议配置Docker镜像加速：

```bash
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": [
    "https://docker.mirrors.ustc.edu.cn",
    "https://hub-mirror.c.163.com",
    "https://mirror.baidubce.com"
  ],
  "runtimes": {
    "nvidia": {
      "path": "nvidia-container-runtime",
      "runtimeArgs": []
    }
  }
}
EOF

sudo systemctl restart docker
```

### 3.2 构建Docker镜像

```bash
# 返回项目根目录
cd /path/to/TFG_ui

# 构建主服务镜像（包含训练、推理、对话功能）
docker-compose build tfg_ui

# 或者单独构建
docker build -t tfg_ui:latest -f Dockerfile .
```

**构建时间**：首次构建约需1-2小时（取决于网络速度）

**构建过程**：
1. 下载CUDA基础镜像（约5GB）
2. 安装系统依赖
3. 安装Miniconda和创建Conda环境
4. 安装Python依赖
5. 编译CUDA扩展（diff-gaussian-rasterization、simple-knn）

**查看构建日志**：
```bash
# 实时查看构建日志
docker-compose build --progress=plain tfg_ui

# 或者后台构建并查看日志
docker-compose build tfg_ui 2>&1 | tee build.log
```

### 3.3 验证镜像构建

```bash
# 查看镜像
docker images | grep tfg_ui

# 测试运行（可选）
docker run --rm --gpus all tfg_ui:latest nvidia-smi
```

---

## 四、项目启动

### 4.1 配置API密钥（可选）

如果需要使用实时对话功能，需要配置LLM API：

```bash
# 创建配置文件
mkdir -p backend/config
cp backend/config/api_config.example.json backend/config/api_config.json

# 编辑配置文件
nano backend/config/api_config.json
```

**配置文件格式**：
```json
{
  "openai": {
    "api_key": "sk-xxxxxxxx",
    "base_url": "https://api.openai.com/v1",
    "model": "gpt-3.5-turbo",
    "enabled": true
  },
  "zhipu": {
    "api_key": "your-zhipu-api-key",
    "base_url": "https://open.bigmodel.cn/api/paas/v4/",
    "model": "glm-4",
    "enabled": true
  },
  "deepseek": {
    "api_key": "sk-your-deepseek-api-key",
    "base_url": "https://api.deepseek.com",
    "model": "deepseek-chat",
    "enabled": true
  }
}
```

**或者使用环境变量**（优先级更高）：
```bash
export OPENAI_API_KEY="sk-xxxxxxxx"
export ZHIPU_API_KEY="your-zhipu-api-key"
export DEEPSEEK_API_KEY="sk-your-deepseek-api-key"
```

### 4.2 启动服务

#### 方式1：使用Docker Compose（推荐）

```bash
# 启动服务
docker-compose up -d

# 查看日志
docker-compose logs -f tfg_ui

# 停止服务
docker-compose down
```

#### 方式2：直接使用Docker

```bash
# 启动容器
docker run -d \
  --name tfg_ui \
  --gpus all \
  -p 5001:5001 \
  -v $(pwd)/static:/app/static \
  -v $(pwd)/TalkingGaussian/data:/app/TalkingGaussian/data \
  -v $(pwd)/TalkingGaussian/output:/app/TalkingGaussian/output \
  -v $(pwd)/backend/config:/app/backend/config \
  -e CUDA_VISIBLE_DEVICES=0 \
  tfg_ui:latest

# 查看日志
docker logs -f tfg_ui
```

### 4.3 访问服务

启动成功后，在浏览器中访问：

```
http://服务器IP:5001
```

或本地访问：

```
http://localhost:5001
```

---

## 五、OpenFace 使用说明（重要）

### 5.1 OpenFace 概述

**OpenFace** 是一个开源的面部分析工具，用于提取面部动作单元（Action Units, AU）数据。在训练 TalkingGaussian 模型时，需要提供 `au.csv` 文件，该文件包含视频中每一帧的面部动作单元数据。

**为什么需要 OpenFace**：
- TalkingGaussian 训练需要 AU 数据来控制面部表情
- AU 数据用于生成更自然的面部动画
- 必须在训练前准备好 `au.csv` 文件

### 5.2 本地安装和运行 OpenFace

#### 5.2.1 下载 OpenFace

**Windows 系统**：
1. 访问 OpenFace 官网：https://github.com/TadasBaltrusaitis/OpenFace
2. 下载预编译版本：`OpenFace_2.2.0_win_x64.zip`
3. 解压到本地目录，如 `C:\OpenFace_2.2.0_win_x64\`

**Linux 系统**：
1. 下载 Linux 版本：`OpenFace_2.2.0_linux_x64.tar.gz`
2. 解压：
   ```bash
   tar -xzf OpenFace_2.2.0_linux_x64.tar.gz
   cd OpenFace_2.2.0_linux_x64
   ```

**macOS 系统**：
1. 下载 macOS 版本或从源码编译
2. 参考官方文档进行安装

#### 5.2.2 运行 OpenFace 提取 AU 数据

**Windows 系统**：
```cmd
# 进入 OpenFace 目录
cd C:\OpenFace_2.2.0_win_x64

# 运行 FeatureExtraction
FeatureExtraction.exe -f "路径\到\训练视频.mp4" -out_dir "输出目录"
```

**Linux/macOS 系统**：
```bash
# 进入 OpenFace 目录
cd OpenFace_2.2.0_linux_x64

# 运行 FeatureExtraction
./FeatureExtraction -f /path/to/training_video.mp4 -out_dir /path/to/output
```

**参数说明**：
- `-f`：输入视频文件路径
- `-out_dir`：输出目录（OpenFace 会在此目录生成 CSV 文件）

**输出文件**：
- OpenFace 会生成一个 CSV 文件，文件名格式为：`<视频名>.csv`
- 该文件包含每一帧的面部特征数据，包括 AU 数据

#### 5.2.3 准备 au.csv 文件

**步骤**：
1. OpenFace 生成的 CSV 文件包含很多列，我们需要的是 AU 相关的列
2. 检查 CSV 文件是否包含以下 AU 列：
   - ` AU01_r`, ` AU02_r`, ` AU04_r`, ` AU05_r`, ` AU06_r`, ` AU07_r`
   - ` AU09_r`, ` AU10_r`, ` AU12_r`, ` AU14_r`, ` AU15_r`, ` AU17_r`
   - ` AU20_r`, ` AU23_r`, ` AU25_r`, ` AU26_r`, ` AU45_r`

3. **方法1：直接使用 OpenFace 的输出**（如果包含所有需要的列）
   ```bash
   # 重命名并移动到项目目录
   cp <OpenFace输出目录>/<视频名>.csv au.csv
   ```

4. **方法2：提取需要的列**（如果 CSV 文件包含很多不需要的列）
   ```python
   import pandas as pd
   
   # 读取 OpenFace 输出的 CSV
   df = pd.read_csv('openface_output.csv')
   
   # 提取需要的 AU 列
   au_columns = [' AU01_r', ' AU02_r', ' AU04_r', ' AU05_r', ' AU06_r', 
                 ' AU07_r', ' AU09_r', ' AU10_r', ' AU12_r', ' AU14_r', 
                 ' AU15_r', ' AU17_r', ' AU20_r', ' AU23_r', ' AU25_r', 
                 ' AU26_r', ' AU45_r']
   
   # 检查哪些列存在
   existing_columns = [col for col in au_columns if col in df.columns]
   
   # 提取存在的列
   au_df = df[existing_columns]
   
   # 保存为 au.csv
   au_df.to_csv('au.csv', index=False)
   ```

### 5.3 上传 au.csv 到服务器

#### 方式1：通过前端上传（推荐）

**使用上传接口**：
```bash
# 使用 curl 命令上传
curl -F "project_id=May" \
     -F "au_file=@au.csv" \
     http://服务器IP:5001/upload_au
```

**参数说明**：
- `project_id`：项目ID，对应数据目录名（如 `May`）
- `au_file`：au.csv 文件路径（使用 `@` 前缀表示文件上传）

**上传后的位置**：
- 文件会保存到：`TalkingGaussian/data/<project_id>/au.csv`
- 例如：`TalkingGaussian/data/May/au.csv`

#### 方式2：直接上传到服务器

**使用 SCP**：
```bash
# 直接上传到服务器对应目录
scp au.csv user@server:/path/to/TFG_ui/TalkingGaussian/data/May/au.csv
```

**使用 rsync**：
```bash
rsync -avz au.csv user@server:/path/to/TFG_ui/TalkingGaussian/data/May/au.csv
```

**注意事项**：
- 确保目录 `TalkingGaussian/data/<project_id>/` 已存在
- 文件名必须是 `au.csv`（小写）
- 文件路径必须正确，训练时会自动读取

### 5.4 验证 au.csv 文件

**在服务器上验证**：
```bash
# 进入项目目录
cd /path/to/TFG_ui

# 检查文件是否存在
ls -lh TalkingGaussian/data/May/au.csv

# 查看文件前几行（验证格式）
head -5 TalkingGaussian/data/May/au.csv

# 检查是否包含必要的 AU 列
python3 -c "import pandas as pd; df = pd.read_csv('TalkingGaussian/data/May/au.csv'); print(df.columns.tolist())"
```

**预期输出**：
- 文件应包含 17 个 AU 列（` AU01_r` 到 ` AU45_r`）
- 行数应与训练视频的帧数一致

### 5.5 常见问题

**Q: OpenFace 运行失败怎么办？**
A: 
- 检查视频格式是否支持（推荐 MP4）
- 确保视频中有清晰的人脸
- 检查 OpenFace 版本是否兼容

**Q: au.csv 文件格式不对怎么办？**
A:
- 确保 CSV 文件包含所有必要的 AU 列
- 检查列名是否正确（注意空格，如 ` AU01_r` 不是 `AU01_r`）
- 确保数据为数值类型

**Q: 训练时找不到 au.csv 怎么办？**
A:
- 检查文件路径：`TalkingGaussian/data/<project_id>/au.csv`
- 确保文件名是 `au.csv`（小写，不是 `AU.csv`）
- 确保文件权限正确（可读）

**Q: 可以在 Docker 容器内运行 OpenFace 吗？**
A:
- 不推荐，因为 OpenFace 本身可能需要 Docker，会导致 docker-in-docker 问题
- 推荐在本地或单独的服务器上运行 OpenFace，生成 au.csv 后上传

### 5.6 完整流程示例

**示例：为 "May" 项目生成 au.csv**

```bash
# 1. 本地运行 OpenFace
cd C:\OpenFace_2.2.0_win_x64
FeatureExtraction.exe -f "D:\videos\May.mp4" -out_dir "D:\openface_output"

# 2. 准备 au.csv（假设 OpenFace 输出为 May.csv）
cd D:\openface_output
# 如果 CSV 包含所有需要的列，直接重命名
copy May.csv au.csv

# 3. 上传到服务器（方式1：使用接口）
curl -F "project_id=May" -F "au_file=@au.csv" http://192.168.1.100:5001/upload_au

# 或方式2：直接上传
scp au.csv root@192.168.1.100:/root/TFG_ui/TalkingGaussian/data/May/au.csv

# 4. 验证上传
ssh root@192.168.1.100
cd /root/TFG_ui
ls -lh TalkingGaussian/data/May/au.csv
head -3 TalkingGaussian/data/May/au.csv
```

---

## 六、功能使用流程

### 6.1 模型训练页面

**功能**：训练个性化的3D说话人头像模型

**使用流程**：

1. **准备训练数据**
   - **训练视频**：上传到 `static/uploads/videos/` 目录
   - **AU 文件**：使用 OpenFace 生成 `au.csv` 文件（见第5节说明）
     - 必须在上传训练视频后，训练开始前准备好
     - 上传方式：使用 `/upload_au` 接口或直接上传到服务器
     - 保存位置：`TalkingGaussian/data/<项目ID>/au.csv`

2. **准备训练视频**
   - 上传训练视频到 `static/uploads/videos/` 目录
   - 视频要求：清晰的人脸视频，建议时长1-5分钟，分辨率至少720p
   - 示例：`static/uploads/videos/May.mp4`

2. **进入训练页面**
   - 在首页点击"模型训练"
   - 或直接访问 `http://服务器IP:5001/model_training`

3. **配置训练参数**
   - **模型选择**：选择 "TalkingGaussian"
   - **训练视频**：选择或输入视频路径（如 `static/uploads/videos/May.mp4`）
   - **GPU选择**：选择使用的GPU（如 "GPU0"）
   - **训练轮数**：设置训练轮数（默认值即可，通常不需要修改）

4. **开始训练**
   - 点击"开始训练"按钮
   - 系统会自动执行以下步骤：
     - 数据预处理（提取帧、面部跟踪、3DMM拟合）
     - 三阶段训练（嘴部训练 → 面部训练 → 融合训练）
   - 训练时间：根据视频长度和GPU性能，通常需要30分钟到数小时

5. **查看训练结果**
   - 训练完成后，页面会显示：
     - 模型路径（如 `output/May`）
     - 预览视频（训练过程中的预览）
     - 参考音频（从训练视频提取的音频）

6. **训练输出位置**
   - 模型文件：`TalkingGaussian/output/<项目名>/`
     - `chkpnt_face_latest.pth`（面部模型）
     - `chkpnt_mouth_latest.pth`（嘴部模型）
     - `chkpnt_fuse_latest.pth`（融合模型）
   - 参考音频：`static/uploads/audios/<项目名>_reference.wav`

**注意事项**：
- 训练过程中不要关闭浏览器或停止服务
- 训练会占用大量GPU显存，建议单独使用一个GPU
- 训练数据会自动保存在 `TalkingGaussian/data/<项目名>/` 目录

---

### 5.2 视频生成页面

**功能**：根据音频生成对应的说话人头像视频

**使用流程**：

1. **进入视频生成页面**
   - 在首页点击"视频生成"
   - 或直接访问 `http://服务器IP:5001/video_generation`

2. **配置生成参数**
   - **模型选择**：选择 "TalkingGaussian"
   - **模型路径**：输入训练好的模型路径（如 `output/May`）
   - **参考音频**：选择或输入音频文件路径
     - 可以使用训练时生成的参考音频：`static/uploads/audios/May_reference.wav`
     - 或使用其他音频文件
   - **GPU选择**：选择使用的GPU
   - **渲染细节等级**：选择0-3（数字越大，细节越多，但速度越慢，默认2）

3. **开始生成**
   - 点击"生成视频"按钮
   - 生成时间：根据音频长度和GPU性能，通常需要1-5分钟

4. **查看生成结果**
   - 生成完成后，页面会显示生成的视频
   - 视频会自动保存到 `static/videos/` 目录（带时间戳，不会覆盖）

**注意事项**：
- 确保模型路径正确（训练完成后会显示）
- 音频格式支持：WAV、MP3、M4A等（会自动转换）
- 生成的视频会包含音频轨道

---

### 5.3 实时对话页面

**功能**：完整的语音交互流程（语音识别 → 大语言模型 → 语音合成 → 视频生成）

**使用流程**：

1. **进入对话页面**
   - 在首页点击"实时对话"
   - 或直接访问 `http://服务器IP:5001/chat_system`

2. **配置对话参数**
   - **模型路径**：输入训练好的模型路径（如 `output/May`）
   - **GPU选择**：选择使用的GPU
   - **LLM API选择**：选择使用的大语言模型API（OpenAI、Zhipu、DeepSeek）
   - **语言类型**：选择中文或英文
   - **语速**：调节语音合成速度（0.5-2.0倍速，默认1.0）
   - **语音克隆参考音频**：选择三种方式之一
     - **当前录音**：使用刚录制的音频作为参考
     - **预设音色**：使用系统预设的音频（default、cross_lingual等）
     - **自定义音频**：上传自定义的参考音频文件

3. **开始对话**
   - **录音**：点击"开始录音"按钮，说话后点击"停止录音"
   - **生成视频**：点击"生成视频"按钮
   - 系统会自动执行以下步骤：
     1. **ASR语音识别**：将录音转换为文本（`input.wav` → `input.txt`）
     2. **LLM生成回复**：调用大语言模型生成回复（`input.txt` → `output.txt`）
     3. **TTS语音合成**：将回复文本合成为语音（`output.txt` + 参考音频 → `tts_output.wav`）
     4. **视频生成**：根据合成语音生成说话人头像视频（`tts_output.wav` → `chat_response.mp4`）

4. **查看对话结果**
   - 生成完成后，页面会显示：
     - 识别的文本（ASR结果）
     - LLM生成的回复文本
     - 生成的说话人头像视频

**注意事项**：
- 需要配置LLM API密钥（见4.1节）
- 录音时建议在安静环境中，清晰发音
- 对话过程可能需要1-3分钟（取决于音频长度和GPU性能）

---

## 七、评测功能

### 6.1 评测概述

项目支持多种评测指标，用于评估生成视频的质量：

- **PSNR**（Peak Signal-to-Noise Ratio）：峰值信噪比，衡量图像质量
- **SSIM**（Structural Similarity Index）：结构相似性指数
- **NIQE**（Natural Image Quality Evaluator）：自然图像质量评估（无需参考图像）
- **FID**（Fréchet Inception Distance）：Fréchet Inception距离
- **LSE-C**（Lip Sync Error - Confidence）：唇形同步错误（置信度）
- **LSE-D**（Lip Sync Error - Distance）：唇形同步错误（距离）

### 6.2 评测前提条件

**必须完成模型训练**：
- 至少完成一次模型训练（见5.1节）
- 训练完成后，会有生成的视频可用于评测

**评测数据准备**：
- **预测视频**：训练完成后生成的视频（位于 `TalkingGaussian/output/<项目名>/train/` 或 `test/` 目录）
- **真实视频**：原始训练视频（位于 `TalkingGaussian/data/<项目名>/<项目名>.mp4`）

**重要提示**：
- 评测使用的是训练完成后生成的视频，不是实时对话生成的视频
- 预测视频通常在 `output/<项目名>/train/` 目录下（如果使用了训练参数）
- 如果结果在 `test/` 目录，需要复制到 `train/` 目录

### 6.3 评测方法

#### 方法1：使用统一评测脚本（推荐）

```bash
# 进入Docker容器
docker exec -it tfg_ui bash

# 进入评测目录
cd TalkingGaussian/evaluation

# 运行统一评测脚本
bash run_all_metrics.sh \
  --pred_dir /app/TalkingGaussian/output/May/train \
  --gt_dir /app/TalkingGaussian/data/May/May.mp4 \
  --output_file /app/test_metrics_may.json
```

**参数说明**：
- `--pred_dir`：预测视频目录或单个视频文件
- `--gt_dir`：真实视频目录或单个视频文件
- `--output_file`：输出JSON文件路径（可选，默认 `metrics.json`）

**输出结果**：
```json
{
  "PSNR": 28.5,
  "SSIM": 0.85,
  "NIQE": 5.2,
  "FID": 12.3,
  "LSE-C": 6.8,
  "LSE-D": 2.1
}
```

#### 方法2：单独运行各指标

```bash
# 进入Docker容器
docker exec -it tfg_ui bash

# 进入评测目录
cd TalkingGaussian/evaluation

# 1. PSNR/SSIM（帧级指标）
conda run -n talking_gaussian --no-capture-output \
  python eval_frame_metrics.py \
  /app/TalkingGaussian/output/May/train/result.mp4 \
  /app/TalkingGaussian/data/May/May.mp4

# 2. NIQE（需要先提取帧）
conda run -n talking_gaussian --no-capture-output \
  python extract_frames.py \
  /app/TalkingGaussian/output/May/train/result.mp4 \
  /app/TalkingGaussian/evaluation/_work/pred_frames

conda run -n tg_niqe --no-capture-output \
  python eval_niqe.py \
  /app/TalkingGaussian/evaluation/_work/pred_frames

# 3. FID（需要预测和真实帧）
conda run -n talking_gaussian --no-capture-output \
  python extract_frames.py \
  /app/TalkingGaussian/data/May/May.mp4 \
  /app/TalkingGaussian/evaluation/_work/gt_frames

conda run -n tg_eval --no-capture-output \
  python eval_fid.py \
  /app/TalkingGaussian/evaluation/_work/pred_frames \
  /app/TalkingGaussian/evaluation/_work/gt_frames

# 4. LSE-C/LSE-D（需要设置SyncNet）
bash setup_syncnet.sh
bash setup_lse.sh

conda run -n talking_gaussian --no-capture-output \
  python eval_lse.py \
  /app/TalkingGaussian/output/May/train \
  --preset wav2lip-real
```

### 6.4 评测注意事项

1. **数据路径**：
   - 在Docker容器内，路径以 `/app/` 开头
   - 预测视频通常在 `output/<项目名>/train/` 目录
   - 如果结果在 `test/` 目录，需要确认是否正确

2. **LSE指标**：
   - 需要先运行 `setup_syncnet.sh` 和 `setup_lse.sh` 设置环境
   - 首次运行会自动下载SyncNet和Wav2Lip相关代码

3. **评测环境**：
   - 不同指标使用不同的Conda环境：
     - `talking_gaussian`：PSNR/SSIM/LSE
     - `tg_niqe`：NIQE
     - `tg_eval`：FID

4. **评测时间**：
   - PSNR/SSIM：较快（几秒到几分钟）
   - NIQE：中等（几分钟）
   - FID：较慢（可能需要10-30分钟）
   - LSE：较慢（可能需要10-30分钟）

### 6.5 评测结果解读

- **PSNR**：数值越大越好（通常>25为较好）
- **SSIM**：数值越大越好（范围0-1，通常>0.8为较好）
- **NIQE**：数值越小越好（通常<6为较好）
- **FID**：数值越小越好（通常<20为较好）
- **LSE-C**：数值越小越好（通常<10为较好）
- **LSE-D**：数值越小越好（通常<3为较好）

---

## 八、常见问题

### 7.1 Git子模块相关问题

**问题**：克隆后子模块目录为空

**解决**：
```bash
cd TalkingGaussian
git submodule update --init --recursive
```

**问题**：子模块初始化失败（网络问题）

**解决**：
- 使用代理或VPN
- 或手动克隆子模块（见2.3节）

**问题**：`.gitmodules` 文件缺失子模块配置

**错误信息**：
```
fatal: No url found for submodule path 'submodules/diff-gaussian-rasterization' in .gitmodules
```

**解决**：
1. 检查并更新 `TalkingGaussian/.gitmodules` 文件，确保包含所有子模块配置（见2.3节问题2）
2. 清理Git缓存并重新初始化：
```bash
cd TalkingGaussian
git rm --cached third_party/Wav2Lip third_party/syncnet_python 2>/dev/null || true
git submodule sync
git submodule update --init --recursive
```

详细解决方案请参考 **2.3 节 - 问题2**。

### 7.2 Docker构建问题

**问题**：构建时网络超时

**解决**：
- 配置Docker镜像加速（见3.1节）
- 或使用代理

**问题**：构建时磁盘空间不足

**解决**：
- 清理Docker缓存：`docker system prune -a`
- 扩展磁盘空间
- 使用 `cleanup_docker_failed.sh` 清理失败残留

**问题**：构建时CUDA编译失败

**解决**：
- 确保使用 `devel` 版本的CUDA镜像（Dockerfile中已配置）
- 检查GPU驱动和CUDA版本兼容性

### 7.3 训练相关问题

**问题**：训练时显存不足

**解决**：
- 使用显存更大的GPU
- 或减少训练视频分辨率

**问题**：训练结果在 `test/` 目录而不是 `train/` 目录

**解决**：
- 这是正常的，取决于训练时使用的参数
- 评测时使用 `test/` 目录的视频即可

### 7.4 评测相关问题

**问题**：评测脚本找不到视频文件

**解决**：
- 确认视频路径正确
- 在Docker容器内使用绝对路径（以 `/app/` 开头）
- 检查视频文件是否存在：`ls -lh /app/TalkingGaussian/output/<项目名>/train/`

**问题**：LSE指标运行失败

**解决**：
- 先运行 `setup_syncnet.sh` 和 `setup_lse.sh`
- 检查SyncNet相关文件是否存在

### 7.5 服务访问问题

**问题**：无法访问服务（5001端口）

**解决**：
- 检查防火墙设置：`sudo ufw allow 5001`
- 检查服务是否运行：`docker-compose ps`
- 查看日志：`docker-compose logs tfg_ui`

---

## 九、附录

### 8.1 相关文档

- `项目结构说明.md`：详细的项目结构说明
- `DOCKER完整指南.md`：Docker详细使用文档
- `README.md`：项目基本说明

### 8.2 技术支持

如遇到问题，请：
1. 查看相关文档
2. 检查日志文件
3. 联系项目维护者


