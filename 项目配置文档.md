# 项目配置文档

本文档提供完整的项目配置和运行指南，帮助老师快速复现项目。

---

## 目录

1. [一、环境准备](#一环境准备)
2. [二、克隆仓库](#二克隆仓库)
3. [三、Docker环境配置](#三docker环境配置)
4. [四、项目启动](#四项目启动)
5. [五、功能使用流程](#五功能使用流程)
6. [六、评测功能](#六评测功能)
7. [七、常见问题](#七常见问题)

---

## 一、环境准备

### 1.1 硬件要求

- **GPU**：NVIDIA GPU，支持CUDA 11.8+，至少8GB显存（推荐16GB+）
- **内存**：至少16GB RAM（推荐32GB+）
- **磁盘空间**：至少100GB可用空间（推荐200GB+）
- **网络**：需要稳定的网络连接（用于下载模型和依赖）

### 1.2 软件要求

- **操作系统**：Ubuntu 20.04+ / CentOS 7+ / 其他Linux发行版
- **Docker**：20.10+（必须）
- **Docker Compose**：1.29+（推荐）
- **NVIDIA Docker**：支持GPU（`nvidia-docker2`）

### 1.3 检查GPU和Docker

```bash
# 检查GPU
nvidia-smi

# 检查Docker
docker --version
docker-compose --version

# 检查NVIDIA Docker支持
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

如果上述命令执行失败，请参考 `DOCKER完整指南.md` 进行安装。

---

## 二、克隆仓库

### 2.1 克隆主仓库

```bash
# 克隆项目仓库
git clone <仓库地址> TFG_ui
cd TFG_ui
```

### 2.2 初始化Git子模块（重要！）

项目包含Git子模块，必须初始化才能正常使用：

```bash
# 进入TalkingGaussian目录
cd TalkingGaussian

# 初始化并更新子模块
git submodule update --init --recursive

# 或者使用以下命令（一步完成）
git submodule update --init --recursive --depth 1
```

**子模块说明**：
- `submodules/simple-knn`：用于Gaussian Splatting的KNN加速
- `submodules/diff-gaussian-rasterization`：Gaussian Splatting的光栅化实现

**验证子模块**：
```bash
# 检查子模块是否已初始化
ls -la submodules/simple-knn/
ls -la submodules/diff-gaussian-rasterization/

# 如果目录为空或不存在，说明子模块未初始化
```

### 2.3 如果子模块初始化失败

如果网络问题导致子模块初始化失败，可以手动处理：

```bash
cd TalkingGaussian

# 方法1：使用代理或镜像（如果有）
git config --global url."https://github.com/".insteadOf "git@github.com:"

# 方法2：手动克隆子模块
cd submodules
git clone https://github.com/ashawkey/diff-gaussian-rasterization.git
git clone https://gitlab.inria.fr/bkerbl/simple-knn.git
cd ..
```

---

## 三、Docker环境配置

### 3.1 配置Docker镜像加速（推荐）

如果在中国大陆，建议配置Docker镜像加速：

```bash
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": [
    "https://docker.mirrors.ustc.edu.cn",
    "https://hub-mirror.c.163.com",
    "https://mirror.baidubce.com"
  ],
  "runtimes": {
    "nvidia": {
      "path": "nvidia-container-runtime",
      "runtimeArgs": []
    }
  }
}
EOF

sudo systemctl restart docker
```

### 3.2 构建Docker镜像

```bash
# 返回项目根目录
cd /path/to/TFG_ui

# 构建主服务镜像（包含训练、推理、对话功能）
docker-compose build tfg_ui

# 或者单独构建
docker build -t tfg_ui:latest -f Dockerfile .
```

**构建时间**：首次构建约需1-2小时（取决于网络速度）

**构建过程**：
1. 下载CUDA基础镜像（约5GB）
2. 安装系统依赖
3. 安装Miniconda和创建Conda环境
4. 安装Python依赖
5. 编译CUDA扩展（diff-gaussian-rasterization、simple-knn）

**查看构建日志**：
```bash
# 实时查看构建日志
docker-compose build --progress=plain tfg_ui

# 或者后台构建并查看日志
docker-compose build tfg_ui 2>&1 | tee build.log
```

### 3.3 验证镜像构建

```bash
# 查看镜像
docker images | grep tfg_ui

# 测试运行（可选）
docker run --rm --gpus all tfg_ui:latest nvidia-smi
```

---

## 四、项目启动

### 4.1 配置API密钥（可选）

如果需要使用实时对话功能，需要配置LLM API：

```bash
# 创建配置文件
mkdir -p backend/config
cp backend/config/api_config.example.json backend/config/api_config.json

# 编辑配置文件
nano backend/config/api_config.json
```

**配置文件格式**：
```json
{
  "openai": {
    "api_key": "sk-xxxxxxxx",
    "base_url": "https://api.openai.com/v1",
    "model": "gpt-3.5-turbo",
    "enabled": true
  },
  "zhipu": {
    "api_key": "your-zhipu-api-key",
    "base_url": "https://open.bigmodel.cn/api/paas/v4/",
    "model": "glm-4",
    "enabled": true
  },
  "deepseek": {
    "api_key": "sk-your-deepseek-api-key",
    "base_url": "https://api.deepseek.com",
    "model": "deepseek-chat",
    "enabled": true
  }
}
```

**或者使用环境变量**（优先级更高）：
```bash
export OPENAI_API_KEY="sk-xxxxxxxx"
export ZHIPU_API_KEY="your-zhipu-api-key"
export DEEPSEEK_API_KEY="sk-your-deepseek-api-key"
```

### 4.2 启动服务

#### 方式1：使用Docker Compose（推荐）

```bash
# 启动服务
docker-compose up -d

# 查看日志
docker-compose logs -f tfg_ui

# 停止服务
docker-compose down
```

#### 方式2：直接使用Docker

```bash
# 启动容器
docker run -d \
  --name tfg_ui \
  --gpus all \
  -p 5001:5001 \
  -v $(pwd)/static:/app/static \
  -v $(pwd)/TalkingGaussian/data:/app/TalkingGaussian/data \
  -v $(pwd)/TalkingGaussian/output:/app/TalkingGaussian/output \
  -v $(pwd)/backend/config:/app/backend/config \
  -e CUDA_VISIBLE_DEVICES=0 \
  tfg_ui:latest

# 查看日志
docker logs -f tfg_ui
```

### 4.3 访问服务

启动成功后，在浏览器中访问：

```
http://服务器IP:5001
```

或本地访问：

```
http://localhost:5001
```

---

## 五、功能使用流程

### 5.1 模型训练页面

**功能**：训练个性化的3D说话人头像模型

**使用流程**：

1. **准备训练视频**
   - 上传训练视频到 `static/uploads/videos/` 目录
   - 视频要求：清晰的人脸视频，建议时长1-5分钟，分辨率至少720p
   - 示例：`static/uploads/videos/May.mp4`

2. **进入训练页面**
   - 在首页点击"模型训练"
   - 或直接访问 `http://服务器IP:5001/model_training`

3. **配置训练参数**
   - **模型选择**：选择 "TalkingGaussian"
   - **训练视频**：选择或输入视频路径（如 `static/uploads/videos/May.mp4`）
   - **GPU选择**：选择使用的GPU（如 "GPU0"）
   - **训练轮数**：设置训练轮数（默认值即可，通常不需要修改）

4. **开始训练**
   - 点击"开始训练"按钮
   - 系统会自动执行以下步骤：
     - 数据预处理（提取帧、面部跟踪、3DMM拟合）
     - 三阶段训练（嘴部训练 → 面部训练 → 融合训练）
   - 训练时间：根据视频长度和GPU性能，通常需要30分钟到数小时

5. **查看训练结果**
   - 训练完成后，页面会显示：
     - 模型路径（如 `output/May`）
     - 预览视频（训练过程中的预览）
     - 参考音频（从训练视频提取的音频）

6. **训练输出位置**
   - 模型文件：`TalkingGaussian/output/<项目名>/`
     - `chkpnt_face_latest.pth`（面部模型）
     - `chkpnt_mouth_latest.pth`（嘴部模型）
     - `chkpnt_fuse_latest.pth`（融合模型）
   - 参考音频：`static/uploads/audios/<项目名>_reference.wav`

**注意事项**：
- 训练过程中不要关闭浏览器或停止服务
- 训练会占用大量GPU显存，建议单独使用一个GPU
- 训练数据会自动保存在 `TalkingGaussian/data/<项目名>/` 目录

---

### 5.2 视频生成页面

**功能**：根据音频生成对应的说话人头像视频

**使用流程**：

1. **进入视频生成页面**
   - 在首页点击"视频生成"
   - 或直接访问 `http://服务器IP:5001/video_generation`

2. **配置生成参数**
   - **模型选择**：选择 "TalkingGaussian"
   - **模型路径**：输入训练好的模型路径（如 `output/May`）
   - **参考音频**：选择或输入音频文件路径
     - 可以使用训练时生成的参考音频：`static/uploads/audios/May_reference.wav`
     - 或使用其他音频文件
   - **GPU选择**：选择使用的GPU
   - **渲染细节等级**：选择0-3（数字越大，细节越多，但速度越慢，默认2）

3. **开始生成**
   - 点击"生成视频"按钮
   - 生成时间：根据音频长度和GPU性能，通常需要1-5分钟

4. **查看生成结果**
   - 生成完成后，页面会显示生成的视频
   - 视频会自动保存到 `static/videos/` 目录（带时间戳，不会覆盖）

**注意事项**：
- 确保模型路径正确（训练完成后会显示）
- 音频格式支持：WAV、MP3、M4A等（会自动转换）
- 生成的视频会包含音频轨道

---

### 5.3 实时对话页面

**功能**：完整的语音交互流程（语音识别 → 大语言模型 → 语音合成 → 视频生成）

**使用流程**：

1. **进入对话页面**
   - 在首页点击"实时对话"
   - 或直接访问 `http://服务器IP:5001/chat_system`

2. **配置对话参数**
   - **模型路径**：输入训练好的模型路径（如 `output/May`）
   - **GPU选择**：选择使用的GPU
   - **LLM API选择**：选择使用的大语言模型API（OpenAI、Zhipu、DeepSeek）
   - **语言类型**：选择中文或英文
   - **语速**：调节语音合成速度（0.5-2.0倍速，默认1.0）
   - **语音克隆参考音频**：选择三种方式之一
     - **当前录音**：使用刚录制的音频作为参考
     - **预设音色**：使用系统预设的音频（default、cross_lingual等）
     - **自定义音频**：上传自定义的参考音频文件

3. **开始对话**
   - **录音**：点击"开始录音"按钮，说话后点击"停止录音"
   - **生成视频**：点击"生成视频"按钮
   - 系统会自动执行以下步骤：
     1. **ASR语音识别**：将录音转换为文本（`input.wav` → `input.txt`）
     2. **LLM生成回复**：调用大语言模型生成回复（`input.txt` → `output.txt`）
     3. **TTS语音合成**：将回复文本合成为语音（`output.txt` + 参考音频 → `tts_output.wav`）
     4. **视频生成**：根据合成语音生成说话人头像视频（`tts_output.wav` → `chat_response.mp4`）

4. **查看对话结果**
   - 生成完成后，页面会显示：
     - 识别的文本（ASR结果）
     - LLM生成的回复文本
     - 生成的说话人头像视频

**注意事项**：
- 需要配置LLM API密钥（见4.1节）
- 录音时建议在安静环境中，清晰发音
- 对话过程可能需要1-3分钟（取决于音频长度和GPU性能）

---

## 六、评测功能

### 6.1 评测概述

项目支持多种评测指标，用于评估生成视频的质量：

- **PSNR**（Peak Signal-to-Noise Ratio）：峰值信噪比，衡量图像质量
- **SSIM**（Structural Similarity Index）：结构相似性指数
- **NIQE**（Natural Image Quality Evaluator）：自然图像质量评估（无需参考图像）
- **FID**（Fréchet Inception Distance）：Fréchet Inception距离
- **LSE-C**（Lip Sync Error - Confidence）：唇形同步错误（置信度）
- **LSE-D**（Lip Sync Error - Distance）：唇形同步错误（距离）

### 6.2 评测前提条件

**必须完成模型训练**：
- 至少完成一次模型训练（见5.1节）
- 训练完成后，会有生成的视频可用于评测

**评测数据准备**：
- **预测视频**：训练完成后生成的视频（位于 `TalkingGaussian/output/<项目名>/train/` 或 `test/` 目录）
- **真实视频**：原始训练视频（位于 `TalkingGaussian/data/<项目名>/<项目名>.mp4`）

**重要提示**：
- 评测使用的是训练完成后生成的视频，不是实时对话生成的视频
- 预测视频通常在 `output/<项目名>/train/` 目录下（如果使用了训练参数）
- 如果结果在 `test/` 目录，需要复制到 `train/` 目录

### 6.3 评测方法

#### 方法1：使用统一评测脚本（推荐）

```bash
# 进入Docker容器
docker exec -it tfg_ui bash

# 进入评测目录
cd TalkingGaussian/evaluation

# 运行统一评测脚本
bash run_all_metrics.sh \
  --pred_dir /app/TalkingGaussian/output/May/train \
  --gt_dir /app/TalkingGaussian/data/May/May.mp4 \
  --output_file /app/test_metrics_may.json
```

**参数说明**：
- `--pred_dir`：预测视频目录或单个视频文件
- `--gt_dir`：真实视频目录或单个视频文件
- `--output_file`：输出JSON文件路径（可选，默认 `metrics.json`）

**输出结果**：
```json
{
  "PSNR": 28.5,
  "SSIM": 0.85,
  "NIQE": 5.2,
  "FID": 12.3,
  "LSE-C": 6.8,
  "LSE-D": 2.1
}
```

#### 方法2：单独运行各指标

```bash
# 进入Docker容器
docker exec -it tfg_ui bash

# 进入评测目录
cd TalkingGaussian/evaluation

# 1. PSNR/SSIM（帧级指标）
conda run -n talking_gaussian --no-capture-output \
  python eval_frame_metrics.py \
  /app/TalkingGaussian/output/May/train/result.mp4 \
  /app/TalkingGaussian/data/May/May.mp4

# 2. NIQE（需要先提取帧）
conda run -n talking_gaussian --no-capture-output \
  python extract_frames.py \
  /app/TalkingGaussian/output/May/train/result.mp4 \
  /app/TalkingGaussian/evaluation/_work/pred_frames

conda run -n tg_niqe --no-capture-output \
  python eval_niqe.py \
  /app/TalkingGaussian/evaluation/_work/pred_frames

# 3. FID（需要预测和真实帧）
conda run -n talking_gaussian --no-capture-output \
  python extract_frames.py \
  /app/TalkingGaussian/data/May/May.mp4 \
  /app/TalkingGaussian/evaluation/_work/gt_frames

conda run -n tg_eval --no-capture-output \
  python eval_fid.py \
  /app/TalkingGaussian/evaluation/_work/pred_frames \
  /app/TalkingGaussian/evaluation/_work/gt_frames

# 4. LSE-C/LSE-D（需要设置SyncNet）
bash setup_syncnet.sh
bash setup_lse.sh

conda run -n talking_gaussian --no-capture-output \
  python eval_lse.py \
  /app/TalkingGaussian/output/May/train \
  --preset wav2lip-real
```

### 6.4 评测注意事项

1. **数据路径**：
   - 在Docker容器内，路径以 `/app/` 开头
   - 预测视频通常在 `output/<项目名>/train/` 目录
   - 如果结果在 `test/` 目录，需要确认是否正确

2. **LSE指标**：
   - 需要先运行 `setup_syncnet.sh` 和 `setup_lse.sh` 设置环境
   - 首次运行会自动下载SyncNet和Wav2Lip相关代码

3. **评测环境**：
   - 不同指标使用不同的Conda环境：
     - `talking_gaussian`：PSNR/SSIM/LSE
     - `tg_niqe`：NIQE
     - `tg_eval`：FID

4. **评测时间**：
   - PSNR/SSIM：较快（几秒到几分钟）
   - NIQE：中等（几分钟）
   - FID：较慢（可能需要10-30分钟）
   - LSE：较慢（可能需要10-30分钟）

### 6.5 评测结果解读

- **PSNR**：数值越大越好（通常>25为较好）
- **SSIM**：数值越大越好（范围0-1，通常>0.8为较好）
- **NIQE**：数值越小越好（通常<6为较好）
- **FID**：数值越小越好（通常<20为较好）
- **LSE-C**：数值越小越好（通常<10为较好）
- **LSE-D**：数值越小越好（通常<3为较好）

---

## 七、常见问题

### 7.1 Git子模块相关问题

**问题**：克隆后子模块目录为空

**解决**：
```bash
cd TalkingGaussian
git submodule update --init --recursive
```

**问题**：子模块初始化失败（网络问题）

**解决**：
- 使用代理或VPN
- 或手动克隆子模块（见2.3节）

### 7.2 Docker构建问题

**问题**：构建时网络超时

**解决**：
- 配置Docker镜像加速（见3.1节）
- 或使用代理

**问题**：构建时磁盘空间不足

**解决**：
- 清理Docker缓存：`docker system prune -a`
- 扩展磁盘空间
- 使用 `cleanup_docker_failed.sh` 清理失败残留

**问题**：构建时CUDA编译失败

**解决**：
- 确保使用 `devel` 版本的CUDA镜像（Dockerfile中已配置）
- 检查GPU驱动和CUDA版本兼容性

### 7.3 训练相关问题

**问题**：训练时显存不足

**解决**：
- 使用显存更大的GPU
- 或减少训练视频分辨率

**问题**：训练结果在 `test/` 目录而不是 `train/` 目录

**解决**：
- 这是正常的，取决于训练时使用的参数
- 评测时使用 `test/` 目录的视频即可

### 7.4 评测相关问题

**问题**：评测脚本找不到视频文件

**解决**：
- 确认视频路径正确
- 在Docker容器内使用绝对路径（以 `/app/` 开头）
- 检查视频文件是否存在：`ls -lh /app/TalkingGaussian/output/<项目名>/train/`

**问题**：LSE指标运行失败

**解决**：
- 先运行 `setup_syncnet.sh` 和 `setup_lse.sh`
- 检查SyncNet相关文件是否存在

### 7.5 服务访问问题

**问题**：无法访问服务（5001端口）

**解决**：
- 检查防火墙设置：`sudo ufw allow 5001`
- 检查服务是否运行：`docker-compose ps`
- 查看日志：`docker-compose logs tfg_ui`

---

## 八、附录

### 8.1 相关文档

- `项目结构说明.md`：详细的项目结构说明
- `DOCKER完整指南.md`：Docker详细使用文档
- `README.md`：项目基本说明

### 8.2 技术支持

如遇到问题，请：
1. 查看相关文档
2. 检查日志文件
3. 联系项目维护者

---

**文档版本**：v1.0  
**最后更新**：2024-12-24

