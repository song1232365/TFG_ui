# TalkingGaussian 后端接口改造总结文档

## 一、改造概述

本次改造将华为云上的 TalkingGaussian 和 CosyVoice 模型完整接入到 TFG_ui 前端系统中，实现了三个核心功能：
1. **视频生成**：根据音频生成说话人头像视频
2. **模型训练**：训练 TalkingGaussian 模型
3. **实时对话**：完整的 ASR → LLM → TTS → 视频生成流程

---

## 二、修改的文件清单

### 1. `backend/video_generator.py`
**修改内容**：添加 TalkingGaussian 分支

**新增功能**：
- 支持 TalkingGaussian 模型推理
- 调用 `TalkingGaussian/run_talkinggaussian.sh` 封装脚本
- 支持 DeepSpeech 和 HuBERT 两种音频特征提取器
- 自动处理输出视频路径和文件查找

**关键参数**：
- `model_name`: "TalkingGaussian"
- `model_param`: 模型路径（如 `output/talking_May`）
- `ref_audio`: 输入音频路径
- `dataset_path`: 数据目录（默认 `TalkingGaussian/data/May`）
- `audio_extractor`: 特征提取器（`deepspeech` 或 `hubert`）
- `gpu_choice`: GPU选择（`GPU0`, `GPU1` 等）

**调用流程**：
```
前端表单 → app.py → video_generator.generate_video()
  → run_talkinggaussian.sh → test_talkinggaussian.py
    → 提取音频特征 → synthesize_fuse.py → 生成视频
      → 裁剪视频 → 合成音轨 → 返回视频路径
```

---

### 2. `backend/model_trainer.py`
**修改内容**：添加 TalkingGaussian 训练分支

**新增功能**：
- 支持 TalkingGaussian 三阶段训练
- 自动检查数据预处理状态
- 如果数据未预处理，自动执行预处理
- 调用 `TalkingGaussian/scripts/train_xx.sh` 训练脚本

**关键参数**：
- `model_choice`: "TalkingGaussian"
- `ref_video`: 训练视频路径
- `gpu_choice`: GPU选择
- `epoch`: 训练轮数（可选，脚本中有默认值）
- `audio_extractor`: 音频特征提取器（可选）

**调用流程**：
```
前端表单 → app.py → model_trainer.train_model()
  → 检查数据预处理 → (如需要) process.py 预处理
    → train_xx.sh → train_mouth.py → train_face.py → train_fuse.py
      → 返回模型路径
```

**数据预处理检查**：
- 检查 `transforms_train.json` 是否存在
- 如果不存在，自动调用 `data_utils/process.py` 进行预处理

---

### 3. `backend/chat_engine.py`
**修改内容**：完善完整对话流程

**新增功能**：
- 完整的实时对话流程：ASR → LLM → CosyVoice → TalkingGaussian
- 新增 `text_to_speech_cosyvoice()` 函数调用 CosyVoice
- 集成视频生成调用

**完整流程**：
```
1. 语音识别（ASR）
   input.wav → SpeechRecognition → input.txt

2. 大模型回复（LLM）
   input.txt → ZhipuAI → output.txt

3. 语音克隆（CosyVoice）
   output.txt + prompt_wav → test_cosyvoice.py → tts_output.wav

4. 视频生成（TalkingGaussian）
   tts_output.wav → video_generator.generate_video() → chat_response.mp4
```

**新增函数**：
- `text_to_speech_cosyvoice()`: CosyVoice 语音克隆封装函数

**关键参数**：
- `model_name`: 模型名称
- `model_param`: TalkingGaussian 模型路径
- `voice_clone`: 参考音频路径（用于语音克隆）
- `api_choice`: LLM API选择（当前使用 ZhipuAI）
- `gpu_choice`: GPU选择
- `dataset_path`: 数据目录（可选）
- `audio_extractor`: 音频特征提取器（可选）

---

## 三、路径变化说明

### 华为云 → 本地项目路径映射

| 功能 | 华为云路径 | 本地路径 | Docker路径 |
|------|-----------|---------|-----------|
| TalkingGaussian脚本 | `/root/TalkingGaussian/` | `./TalkingGaussian/` | `/app/TalkingGaussian/` |
| CosyVoice脚本 | `/root/TFG_ui/CosyVoice/test_cosyvoice.py` | `./CosyVoice/test_cosyvoice.py` | `/app/CosyVoice/test_cosyvoice.py` |
| 数据目录 | `/root/TalkingGaussian/data/` | `./TalkingGaussian/data/` | `/app/TalkingGaussian/data/` |
| 模型目录 | `/root/TalkingGaussian/output/` | `./TalkingGaussian/output/` | `/app/TalkingGaussian/output/` |
| 输出视频 | `/root/TalkingGaussian/static/videos/` | `./static/videos/` | `/app/TFG_ui/static/videos/` |

### 路径处理策略

1. **相对路径**：本地开发使用相对路径（如 `./TalkingGaussian/`）
2. **绝对路径**：Docker 环境使用绝对路径（如 `/app/TalkingGaussian/`）
3. **路径检查**：所有关键路径都有存在性检查，失败时返回默认路径

#### 路径统一实现（已实现）

**问题**：不同模块返回和接收的路径格式不统一
- `model_trainer.py` 返回完整路径：`"TalkingGaussian/output/May"`
- `video_generator.py` 接收的可能是完整路径或相对路径
- `run_talkinggaussian.sh` 需要相对路径：`"output/talking_May"`

**解决方案**：
1. **`normalize_model_path()` 函数**（`video_generator.py`）：
   - 统一模型路径格式为相对于 TalkingGaussian 目录的路径
   - 支持多种输入格式：`"output/talking_May"`、`"TalkingGaussian/output/talking_May"`、`"/app/TalkingGaussian/output/talking_May"`
   - 统一输出格式：`"output/talking_May"`

2. **`normalize_dataset_path()` 函数**（`video_generator.py`）：
   - 统一数据目录路径格式
   - 支持多种输入格式：`"data/May"`、`"TalkingGaussian/data/May"`、`"/app/TalkingGaussian/data/May"`
   - 统一输出格式：`"data/May"`

3. **`validate_model_path()` 函数**（`video_generator.py`）：
   - 验证模型路径是否存在
   - 检查模型检查点文件（`chkpnt_fuse_latest.pth`）是否存在
   - 返回验证结果、统一后的路径和错误信息

**修改位置**：
- `video_generator.py`：添加路径统一和验证函数，在调用脚本前统一路径格式并验证
- `model_trainer.py`：返回相对路径格式（`"output/May"`）而不是完整路径
- `chat_engine.py`：默认值改为相对路径格式（`"output/talking_May"`）

---

## 四、接口参数说明

### 1. 视频生成接口 (`/video_generation`)

**前端表单字段**：
```html
- model_name: "TalkingGaussian" 或 "SyncTalk"
- model_param: 模型目录路径（如 "output/talking_May"）
- ref_audio: 参考音频路径（如 "static/audios/input.wav"）
- gpu_choice: "GPU0" 或 "GPU1"
- target_text: 目标文字（可选，当前未使用）
```

**后端处理**：
- 如果 `model_name == "TalkingGaussian"`，调用 TalkingGaussian 推理
- 如果 `model_name == "SyncTalk"`，调用 SyncTalk 推理（保持原有逻辑）

**返回**：
```json
{
  "status": "success",
  "video_path": "static/videos/talkinggaussian_xxx.mp4"
}
```

---

### 2. 模型训练接口 (`/model_training`)

**前端表单字段**：
```html
- model_choice: "TalkingGaussian" 或 "SyncTalk"
- ref_video: 训练视频路径（如 "TalkingGaussian/data/May/May.mp4"）
- gpu_choice: "GPU0" 或 "GPU1"
- epoch: 训练轮数（可选）
- custom_params: 自定义参数（可选，当前未使用）
```

**后端处理**：
- 如果 `model_choice == "TalkingGaussian"`：
  1. 检查数据是否已预处理
  2. 如未预处理，自动执行预处理
  3. 调用训练脚本进行三阶段训练
- 如果 `model_choice == "SyncTalk"`，调用 SyncTalk 训练（保持原有逻辑）

**返回**：
```json
{
  "status": "success",
  "video_path": "TalkingGaussian/output/talking_May"  // 模型路径
}
```

---

### 3. 实时对话接口 (`/chat_system`)

**前端表单字段**：
```html
- model_name: 模型名称（当前未直接使用，但保留）
- model_param: TalkingGaussian 模型路径
- voice_clone: 参考音频路径（用于 CosyVoice）
- api_choice: LLM API选择（当前固定使用 ZhipuAI）
```

**前端录音**：
- 通过 `/save_audio` 接口保存到 `static/audios/input.wav`

**后端处理流程**：
1. **ASR**：`input.wav` → `input.txt`
2. **LLM**：`input.txt` → `output.txt`
3. **TTS**：`output.txt` + `voice_clone` → `tts_output.wav`
4. **Video**：`tts_output.wav` → `chat_response.mp4`

**返回**：
```json
{
  "status": "success",
  "video_path": "static/videos/chat_response.mp4"
}
```

---

## 五、环境调用说明

### 本地开发环境

**TalkingGaussian**：
- 需要在 `talking_gaussian` conda 环境中运行
- 或确保当前 Python 环境包含所需依赖

**CosyVoice**：
- 需要在 `cosyvoice` conda 环境中运行
- 或确保当前 Python 环境包含所需依赖

**调用方式**：
```python
# 直接调用（假设环境已激活）
subprocess.run(['python', 'TalkingGaussian/test_talkinggaussian.py', ...])
```

---

### Docker 环境

**推荐方案**：使用 `conda run` 切换环境

```python
# TalkingGaussian 调用
subprocess.run([
    '/opt/conda/bin/conda', 'run', '-n', 'talking_gaussian', '--no-capture-output',
    'python', '/app/TalkingGaussian/test_talkinggaussian.py',
    ...
], cwd='/app')

# CosyVoice 调用
subprocess.run([
    '/opt/conda/bin/conda', 'run', '-n', 'cosyvoice', '--no-capture-output',
    'python', '/app/CosyVoice/test_cosyvoice.py',
    ...
], cwd='/app')
```

**环境变量设置**：
```python
env = os.environ.copy()
env['CUDA_VISIBLE_DEVICES'] = gpu_id  # 设置GPU
```

---

## 六、关键脚本说明

### 1. `TalkingGaussian/run_talkinggaussian.sh`
**用途**：TalkingGaussian 推理封装脚本

**参数**：
- `--wav`: 输入音频路径
- `--out`: 输出视频路径
- `--extractor`: 音频特征提取器（deepspeech/hubert）
- `--dataset`: 数据目录
- `--model`: 模型路径

**内部调用**：
- 调用 `test_talkinggaussian.py` 执行完整流程

---

### 2. `TalkingGaussian/test_talkinggaussian.py`
**用途**：TalkingGaussian 完整推理流程

**功能**：
1. 提取音频特征（DeepSpeech 或 HuBERT）
2. 调用 `synthesize_fuse.py` 生成视频
3. 裁剪视频到音频时长
4. 合成音轨

**输出**：
- `test_result/{audio_name}_final.mp4`

---

### 3. `CosyVoice/test_cosyvoice.py`
**用途**：CosyVoice 语音克隆

**参数**：
- `--model_dir`: CosyVoice 模型目录
- `--prompt_wav`: 参考音频
- `--prompt_text`: 参考音频文本
- `--tts_text`: 要合成的文本
- `--language`: 语言（zh/en）
- `--output_file`: 输出文件名

**输出**：
- `test_result/{output_file}_0.wav`（可能带索引）

---

### 4. `TalkingGaussian/scripts/train_xx.sh`
**用途**：TalkingGaussian 三阶段训练脚本

**参数**：
- `$1`: 数据目录
- `$2`: 输出目录（workspace）
- `$3`: GPU ID

**内部流程**：
1. `train_mouth.py` - 训练嘴部
2. `train_face.py` - 训练脸部
3. `train_fuse.py` - 融合训练
4. `synthesize_fuse.py` - 测试
5. `metrics.py` - 评价

---

## 七、错误处理

### 1. 文件不存在检查
- 所有关键文件都有存在性检查
- 失败时返回默认路径或错误信息

### 2. 命令执行失败
- 捕获 `subprocess.CalledProcessError`
- 打印错误输出和标准输出
- 返回默认视频路径

### 3. 异常处理
- 使用 `try-except` 捕获所有异常
- 打印详细错误信息和堆栈跟踪
- 确保不会导致 Flask 应用崩溃

---

## 八、注意事项

### 1. 路径问题
- **相对路径 vs 绝对路径**：确保在正确的目录下执行命令
- **Docker 环境**：使用绝对路径 `/app/...`
- **本地环境**：使用相对路径 `./TalkingGaussian/...`

### 2. 环境切换
- **本地开发**：需要手动激活对应的 conda 环境
- **Docker**：使用 `conda run` 自动切换环境

### 3. GPU 设置
- 通过 `CUDA_VISIBLE_DEVICES` 环境变量设置
- `GPU0` → `CUDA_VISIBLE_DEVICES=0`
- `GPU1` → `CUDA_VISIBLE_DEVICES=1`

### 4. API Key 安全
- `chat_engine.py` 中的 ZhipuAI API Key 应该从环境变量读取
- 当前代码：`os.getenv('ZHIPU_API_KEY', 'default_key')`
- **建议**：在 Docker 或部署环境中使用环境变量

---

## 九、测试建议

### 1. 视频生成测试
```bash
# 测试 TalkingGaussian 推理
curl -X POST http://localhost:5001/video_generation \
  -F "model_name=TalkingGaussian" \
  -F "model_param=output/talking_May" \
  -F "ref_audio=static/audios/test.wav" \
  -F "gpu_choice=GPU0"
```

### 2. 模型训练测试
```bash
# 测试 TalkingGaussian 训练
curl -X POST http://localhost:5001/model_training \
  -F "model_choice=TalkingGaussian" \
  -F "ref_video=TalkingGaussian/data/May/May.mp4" \
  -F "gpu_choice=GPU0" \
  -F "epoch=1000"
```

### 3. 实时对话测试
```bash
# 1. 先上传音频
curl -X POST http://localhost:5001/save_audio \
  -F "audio=@test.wav"

# 2. 触发对话
curl -X POST http://localhost:5001/chat_system \
  -F "model_param=output/talking_May" \
  -F "voice_clone=CosyVoice/asset/zero_shot_prompt.wav"
```

---

## 十、后续优化建议

### 1. 异步处理
- 训练和推理都是耗时操作，建议使用异步任务队列（如 Celery）
- 前端可以轮询任务状态或使用 WebSocket

### 2. 进度反馈
- 训练过程中可以输出进度日志
- 前端可以通过 Server-Sent Events (SSE) 实时显示进度

### 3. 错误信息返回
- 当前错误信息只打印到控制台
- 建议返回详细的错误信息给前端，方便调试

### 4. 参数验证
- 添加更严格的参数验证
- 检查文件格式、路径有效性等

### 5. 资源管理
- 训练和推理占用 GPU 资源，建议添加资源锁
- 避免同时运行多个训练任务

---

## 十一、总结

本次改造成功将 TalkingGaussian 和 CosyVoice 完整接入到 TFG_ui 系统中，实现了：

✅ **视频生成功能**：支持 TalkingGaussian 推理，生成说话人头像视频  
✅ **模型训练功能**：支持 TalkingGaussian 三阶段训练，自动数据预处理  
✅ **实时对话功能**：完整的 ASR → LLM → TTS → Video 流程  

所有修改都保持了与原有 SyncTalk 接口的兼容性，前端无需修改即可使用新功能。

---

**文档版本**：v1.0  
**最后更新**：2025-01-XX  
**作者**：AI Assistant

